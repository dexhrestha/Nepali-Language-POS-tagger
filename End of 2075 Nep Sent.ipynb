{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'csv/nepsent-1.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['tag','word']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document:  [('महिला', 'NN'), ('समालोचक', 'NN'), ('र', 'CC'), ('नेपाली', 'JX'), ('समालोचना', 'NN'), ('।', 'YF')]\n"
     ]
    }
   ],
   "source": [
    "#Convert CSV to nltk word ,tag form\n",
    "corpus= []\n",
    "temp = []\n",
    "for word,tag in zip(df['word'],df['tag']):\n",
    "    if word != '.':\n",
    "#         word = stemmer.stem(str(word))\n",
    "        temp.append((word,tag))\n",
    "    else:\n",
    "        corpus.append(temp)\n",
    "        temp=[]\n",
    "print(\"Sample document: \",corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence:  ['समालोचनालेखन', 'का', 'लागि', 'पर्याप्त', 'अध्ययन', 'को', 'आवश्यकता', 'मात्र', 'ले', 'पुग्दैन', ',', 'विवेचना', 'र', 'विश्लेषण', 'गर्ने', 'क्षमता', 'को', 'पनि', 'आवश्यकता', 'पर्दछ', '।', '।']\n",
      "Sample sentence tags:  ['NN', 'IKO', 'II', 'JX', 'NN', 'IKM', 'NN', 'TT', 'IE', 'VVYN1', 'YM', 'NN', 'CC', 'NN', 'VN', 'NN', 'IKM', 'TT', 'NN', 'VVYN1', 'YF', 'YF']\n"
     ]
    }
   ],
   "source": [
    "#Seperate word and tags into attributes and labels\n",
    "sentences = []\n",
    "sentence_tags = []\n",
    "\n",
    "for sentence in corpus:\n",
    "    if len(sentence)<200:\n",
    "        x=[]\n",
    "        y=[]\n",
    "        for word in sentence:\n",
    "            x.append(word[0])\n",
    "            y.append(word[1])\n",
    "        if len(x) > 0:\n",
    "            sentences.append(x)\n",
    "            sentence_tags.append(y)\n",
    "print(\"Sample sentence: \",sentences[10])\n",
    "print(\"Sample sentence tags: \",sentence_tags[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tags:  {'VDM', 'IKX', 'VS', 'VOYX2', 'VOYN1', 'UU', 'PRF', 'QQ', 'DDX', 'VVYX2', 'MOM', 'PRFKX', 'CSB', 'PMXKM', 'VCN', 'YB', 'FO', 'DGF', 'VVMX2', 'PTH', 'VCM', 'CC', 'DJM', 'VR', 'FB', 'YM', 'RK', 'FF', 'VOMX2', 'VVTN1', 'VI', 'PXR', 'RD', 'DDM', 'PRFKF', 'JT', 'IKM', 'VVMX1', 'DGO', 'VVTN1F', 'NN', 'VDF', 'PMX', 'PRFKM', 'VVYN1F', 'DJX', 'DDO', 'IA', 'FZ', 'JO', 'FU', 'YQ', 'MM', 'PXH', 'CSA', 'VOMX1', 'RR', 'PTNKX', 'MOX', 'JX', 'JF', 'VVYN1', 'DKM', 'PTNKM', 'MLO', 'PMXKF', 'VDX', 'VVTX2', 'IKO', 'IE', 'PMXKO', 'DKX', 'VE', 'JM', 'DGX', 'PTN', 'DKF', 'PTMKF', 'FS', 'PTMKO', 'PTM', 'IKF', 'PTMKX', 'YF', 'MLF', 'DKO', 'DGM', 'PRFKO', 'II', 'NP', 'PMXKX', 'MLX', 'VQ', 'IH', 'VN', 'VVYM1F', 'PTMKM', 'VCH', 'TT', 'RJ', 'VDO'}\n"
     ]
    }
   ],
   "source": [
    "#Convert labels to numbers\n",
    "labels = set()\n",
    "for sentence in sentence_tags:\n",
    "    for tag in sentence:\n",
    "        labels.add(tag)\n",
    "        \n",
    "tag2index = {t: i + 1 for i, t in enumerate(list(labels))}\n",
    "print(\"Total number of tags: \",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagsent2int(sent_tag):\n",
    "    \n",
    "    return [tag2index[tag] for tag in sent_tag]\n",
    "\n",
    "sentence_tags = list(map(tagsent2int,sentence_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert label nums to categorical\n",
    "def to_categorical(sequences,categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample encoded doc 0 :  [[129, 811, 8, 27, 127, 2], [2530, 1788, 2]]  Shape:  (16633,)\n"
     ]
    }
   ],
   "source": [
    "#Preprocess text to numbers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "t = Tokenizer(lower=False, oov_token='-PAD-')\n",
    "t.fit_on_texts(sentences)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "encoded_docs = t.texts_to_sequences(sentences)\n",
    "\n",
    "print(\"Sample encoded doc 0 : \",encoded_docs[:2],\" Shape: \" ,np.asarray(encoded_docs).shape)\n",
    "\n",
    "max_length = len(max(sentences,key=len))\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
