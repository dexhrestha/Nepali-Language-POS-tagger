{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'csv/testdex.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['tag','word']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document:  [('महिला', 'NN'), ('समालोचक', 'NN'), ('र', 'CC'), ('नेपाली', 'JX'), ('समालोचना', 'NN'), ('।', 'YF')]\n"
     ]
    }
   ],
   "source": [
    "#Convert CSV to nltk word ,tag form\n",
    "corpus= []\n",
    "temp = []\n",
    "for word,tag in zip(df['word'],df['tag']):\n",
    "    if word != '.':\n",
    "#         word = stemmer.stem(str(word))\n",
    "        temp.append((word,tag))\n",
    "    else:\n",
    "        corpus.append(temp)\n",
    "        temp=[]\n",
    "print(\"Sample document: \",corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence:  ['समालोचनालेखन', 'का', 'लागि', 'पर्याप्त', 'अध्ययन', 'को', 'आवश्यकता', 'मात्र', 'ले', 'पुग्दैन', ',', 'विवेचना', 'र', 'विश्लेषण', 'गर्ने', 'क्षमता', 'को', 'पनि', 'आवश्यकता', 'पर्दछ', '।', '।']\n",
      "Sample sentence tags:  ['NN', 'IKO', 'II', 'JX', 'NN', 'IKM', 'NN', 'TT', 'IE', 'VVYN1', 'YM', 'NN', 'CC', 'NN', 'VN', 'NN', 'IKM', 'TT', 'NN', 'VVYN1', 'YF', 'YF']\n"
     ]
    }
   ],
   "source": [
    "#Seperate word and tags into attributes and labels\n",
    "sentences = []\n",
    "sentence_tags = []\n",
    "\n",
    "for sentence in corpus:\n",
    "    if len(sentence)<200:\n",
    "        x=[]\n",
    "        y=[]\n",
    "        for word in sentence:\n",
    "            x.append(word[0])\n",
    "            y.append(word[1])\n",
    "        if len(x) > 0:\n",
    "            sentences.append(x)\n",
    "            sentence_tags.append(y)\n",
    "print(\"Sample sentence: \",sentences[10])\n",
    "print(\"Sample sentence tags: \",sentence_tags[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tags:  {'JX', 'IKM', 'VOYN1', 'DGF', 'DKM', 'VDF', 'NN', 'PXR', 'PMXKX', 'PRFKM', 'MLX', 'DDX', 'RK', 'DKX', 'DGM', 'VDX', 'VOMX2', 'VI', 'VDM', 'PMXKF', 'DGX', 'IH', 'VVYX2', 'PTMKM', 'VCN', 'DGO', 'PRFKF', 'CSB', 'IKO', 'MLO', 'JT', 'VDO', 'DDM', 'VCM', 'PRFKX', 'MOX', 'PMXKO', 'FF', 'JM', 'RJ', 'DJM', 'TT', 'FZ', 'MM', 'PMX', 'VVTX2', 'FU', 'PXH', 'NP', 'DKF', 'PMXKM', 'QQ', 'IKX', 'DKO', 'RR', 'UU', 'YB', 'PTH', 'YQ', 'RD', 'PTMKF', 'MLF', 'VR', 'PRF', 'PRFKO', 'FS', 'PTM', 'VVTN1', 'VVMX2', 'YF', 'FO', 'YM', 'PTNKX', 'VOMX1', 'II', 'FB', 'CSA', 'VE', 'VVYN1', 'VVYM1F', 'VVYN1F', 'IA', 'PTN', 'PTMKX', 'VN', 'CC', 'VCH', 'IKF', 'DJX', 'JF', 'IE', 'DDO', 'PTMKO', 'PTNKM', 'VVMX1', 'JO', 'VS', 'VOYX2', 'VVTN1F', 'MOM', 'VQ'}\n"
     ]
    }
   ],
   "source": [
    "#Convert labels to numbers\n",
    "labels = set()\n",
    "for sentence in sentence_tags:\n",
    "    for tag in sentence:\n",
    "        labels.add(tag)\n",
    "        \n",
    "tag2index = {t: i + 1 for i, t in enumerate(list(labels))}\n",
    "print(\"Total number of tags: \",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagsent2int(sent_tag):\n",
    "    \n",
    "    return [tag2index[tag] for tag in sent_tag]\n",
    "\n",
    "sentence_tags = list(map(tagsent2int,sentence_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert label nums to categorical\n",
    "def to_categorical(sequences,categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample encoded doc 0 :  [[129, 811, 8, 27, 127, 2], [2530, 1788, 2]]  Shape:  (16633,)\n"
     ]
    }
   ],
   "source": [
    "#Preprocess text to numbers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "t = Tokenizer(lower=False, oov_token='-PAD-')\n",
    "t.fit_on_texts(sentences)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "encoded_docs = t.texts_to_sequences(sentences)\n",
    "\n",
    "print(\"Sample encoded doc 0 : \",encoded_docs[:2],\" Shape: \" ,np.asarray(encoded_docs).shape)\n",
    "\n",
    "max_length = len(max(sentences,key=len))\n",
    "\n",
    "padded_docs = pad_sequences(encoded_docs[:2], maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bd2ef64501d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_keys' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "new embeddings_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "#     print(word)\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
